@SECTION Source and Bytecode Optimization

The bytecode optimizer works on two levels: source-to-source
optimizing transformations and LAP-level peephole optimizations. It's
possible to control optimization level by setting the
@var{byte-optimize} variable (defined in @file{bytecomp.el}) to
@code{none}, @code{all}, @code{source-level} or @code{byte-level}.

The optimizing framework itself resides in @file{byte-opt.el}.

The source-to-source optimizer entry point is the
@code{byte-optimize-form} function. It works on macroexpanded forms,
recursively looking for function calls and special forms that have
optimising functions defined for them.

The peephole optimizer (see @code{byte-optimize-lapcode}) function
works on LAP directly. It goes through the instruction sequence using
a window of 3 instructions to look for subsequences that can be
dropped or replaced with more efficient versions.

Both optimizers work until a fixpoint is reached, i.e. all the
transformations are applied until there are not further changes
possible.


@itemize
@item
constant folding
@itemize
@item
removal of unreachable code;
@item
detecting and replacing sequences of operations with an equivalent primitive
@item
removal of calls to side-effectless functions whose return-value is unused;
@item
compile-time evaluation of safe constant forms, such as
(@code{consp},  @code{nil}, and @code{(ash 1 6)}
@item
open-coding of literal lambdas;
@item
peephole optimization of emitted code;
@item
trivial functions are left uncompiled for speed.
@end itemize

@item
support for inline functions;
@item
compile-time evaluation of arbitrary expressions;
@item
compile-time warning messages for:

@itemize
@item
functions being redefined with incompatible arglists;
@item
functions being redefined as macros, or vice-versa;
@item
functions or macros defined multiple times in the same file;
@item
functions being called with the incorrect number of arguments;
@item
functions being called which are not defined globally, in the
file, or as autoloads;
@item
assignment and reference of undeclared free variables;
@item
various syntax errors;
@end itemize

@item
correct compilation of nested @code{defuns}, @code{defmacros},
@code{defvars} and @code{defsubsts};
@item
correct compilation of top-level uses of macros;
@item
the ability to generate a histogram of functions called.
@end itemize

@subsection Source-to-source Transformations

All source-to-source transformations are performed by the
@code{byte-optimize-form} function. It's possible to run
@code{byte-optimize-form} on any well-formed form. E.g.,
@code{(byte-optimize-form '(if t 1 2))} returns @code{1}.

Given a form the @code{byte-optimize-form} function performs
transformations in two ways: first it runs the
@code{byte-optimize-form-code-walker} function; then it checks if the
current form is both a function application and the function symbol
has a specialized optimizing function defined for it in the
@code{byte-optimizer} property.

@code{byte-optimize-form-code-walker} recognizes special forms
(@code{if}, @code{let}, @code{let*}, @code{lambda}, @code{closure},
...) and, having performed some sanity checks, recursively runs
@code{byte-optimize-form} on subforms. Here's an example
transformation of the @code{if} special form:

@example
;; sanity checks
(when (< (length form) 3)
	     (byte-compile-warn "too few arguments for `if'"))

;; simplify the form by optimizing subforms
(cons fn
  (cons (byte-optimize-form (nth 1 form) nil)
    (cons
      (byte-optimize-form (nth 2 form) for-effect)
      (byte-optimize-body (nthcdr 3 form) for-effect))))
@end example

The @code{byte-optimizer} symbol property is defined for most of the
built-in side-effect-free functions. E.g. it is defined for some of
the basic math functions in @file{byte-opt.el}:

@example
(put '+   'byte-optimizer 'byte-optimize-plus)
(put '*   'byte-optimizer 'byte-optimize-multiply)
(put '-   'byte-optimizer 'byte-optimize-minus)
(put '/   'byte-optimizer 'byte-optimize-divide)
(put 'max 'byte-optimizer 'byte-optimize-associative-math)
(put 'min 'byte-optimizer 'byte-optimize-associative-math)
@end example

This is how constant folding works in the compiler. The same approach
is also used for dead code elimination for built-in forms:

@example
(put 'and   'byte-optimizer 'byte-optimize-and)
(put 'or    'byte-optimizer 'byte-optimize-or)
(put 'cond  'byte-optimizer 'byte-optimize-cond)
(put 'if    'byte-optimizer 'byte-optimize-if)
(put 'while 'byte-optimizer 'byte-optimize-while)
@end example

@subsection Peephole Optimization

TODO

@subsection Constant Folding

In cases were constants can be evaluated at compile time to come up
with simpler results, that is done.

@code{(defun constant-fold-eg() (+ 1 2))} generates:
@c ((lexical . t) (optimize . nil))
@example
PC  Byte  Instruction
 0  192   constant[0] 1
 1  193   constant[1] 2
 2   92   plus
 3  135   return

Constants Vector: [1 2]
@end example

while with optimization we get:
@c @code{(defun constant-fold-eg() (+ 1 2))} generates:
@c ((lexical . t) (optimize . t))
@example
PC  Byte  Instruction
 0  192   constant[0] 3
 1  135   return

Constants Vector: [3]
@end example

In
@uref{https://lists.gnu.org/archive/html/emacs-devel/2018-04/msg00018.html,
Floating-point constant folding in Emacs byte compile} the notion was
put forth that optimization has to be portable over improving
code. (The issue here was compiling Emacs with larger integers allowed
for larger possibiles of constant folding).

Although Emacs can be compiled with different for integers and floats
depending the setting of @code{--with-wide-int}, for portability,
Emacs will assume in bytecode the smaller value of integers and will
skip opportunities that would assume larger integers.

@subsection Unreachable Code

If there is no way code can be reached, it is removed. This optimization
interacts with the previous optimization: constant propagation.

With bytecode optimization and lexicals scoping off:
@c @code{(defun dead-code-or-eg(a) (or t a))} generates:
@c @c ((lexical . nil) (optimize . nil))

@example
@group
(defun dead-code-eg(a)
   (or t a))
@end group
@end example

generates:
@example
@group
PC  Byte  Instruction
 0  193   constant[1] t
 1  134   goto-if-not-nil-else-pop [5]
           5
           0
 4    8   varref[0] a
 5  135   return

Constants Vector: [a t]
@end group
@end example

On the other hand, with bytecode-optimization we get:
@c @code{(defun dead-code-or-eg(a) (or t a))} generates:
@c ((lexical . t) (optimize . t))
@example
@group
PC  Byte  Instruction
 0  192   constant[0] t
 1  135   return

Constants Vector: [t]
@end group
@end example

@subsection Strength Reduction

The optimizer can recognize when there is primative instructions that
implements an equivalent longer set of instructions.

For example without optimization:

@code{(defun strength-reduce-eg(a) (+ a 1))} generates:
@c ((lexical . nil) (optimize . nil))
@example
@group
PC  Byte  Instruction
 0    8   varref[0] a
 1  193   constant[1] 1
 2   92   plus
 3  135   return

Constants Vector: [a 1]
@end group
@end example

However with optimizaion
@code{(defun strength-reduce-opt-eg(a) (+ a 1))} generates:
@c ((lexical . nil) (optimize . t))
@example
@group
PC  Byte  Instruction
 0    8   varref[0] a
 1   84   add1
 2  135   return

Constants Vector: [a]
@end group
@end example

Notice that the optimizer took advantage of the commutative property of addition
and treated @code{(+ a 1)} as the same thing as @code{(+ 1 a)}.
